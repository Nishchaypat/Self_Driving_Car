{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5330ed7e-e8ef-4cd7-9925-d754b323837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "import datetime\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "#tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# dataset and preprocessing\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from vision.datasets.open_images import ImagesDataset\n",
    "from vision.ssd.data_preprocessing import TrainAugmentation, TestTransform\n",
    "\n",
    "# learning rate scheduler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR\n",
    "\n",
    "# networks\n",
    "from vision.utils.misc import Timer, freeze_net_layers, store_labels\n",
    "from vision.ssd.ssd import MatchPrior\n",
    "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd\n",
    "from vision.ssd.config import mobilenetv1_ssd_config\n",
    "\n",
    "#loss\n",
    "from vision.nn.multibox_loss import MultiboxLoss\n",
    "\n",
    "from evaluators import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce6f097-3332-401c-b517-e21c13d5886d",
   "metadata": {},
   "source": [
    "Default model location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaf3026d-58c9-43ad-bc1d-b6a212f49afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PRETRAINED_MODEL='models/mobilenet-v1-ssd-mp-0_675.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d3e520-bfea-4bca-9bf0-bd00f59b08f7",
   "metadata": {},
   "source": [
    "remove checkpoint and tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c815afc-f912-4a3f-9d84-9e1b3253e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_params = {}\n",
    "\n",
    "arg_params[\"dataset_type\"] = \"open_images\"\n",
    "arg_params[\"datasets\"] = [\"/scratch/sshrestha8/Workshop/Day4/data\"]\n",
    "arg_params[\"balance_data\"] = True\n",
    "arg_params[\"net\"] = \"mb1-ssd\"\n",
    "arg_params[\"resolution\"] = 300\n",
    "arg_params[\"freeze_base_net\"] = True\n",
    "arg_params[\"freeze_net\"] = True\n",
    "arg_params[\"mb2_width_mult\"] = 1.0\n",
    "arg_params[\"base_net\"] = \"\"\n",
    "arg_params[\"pretrained_ssd\"] = \"models/mobilenet-v1-ssd-mp-0_675.pth\"\n",
    "#arg_params[\"resume\"] = \"models/mb1-ssd-Epoch-99-Loss-7.836331605911255.pth\"\n",
    "\n",
    "arg_params[\"lr\"] = 0.01\n",
    "arg_params[\"momentum\"] = 0.9\n",
    "arg_params[\"weight_decay\"] = 5e-4\n",
    "arg_params[\"gamma\"] = 0.1\n",
    "arg_params[\"base_net_lr\"] = 0.001\n",
    "arg_params[\"extra_layers_lr\"] = None\n",
    "arg_params[\"scheduler\"] = \"cosine\"\n",
    "arg_params[\"milestones\"] = \"80,100\"\n",
    "arg_params[\"t_max\"] = 100\n",
    "arg_params[\"batch_size\"] = 4\n",
    "arg_params[\"num_epochs\"] = 100\n",
    "arg_params[\"num_workers\"] = 2\n",
    "arg_params[\"validation_epochs\"] = 1\n",
    "arg_params[\"validation_mean_ap\"] = True\n",
    "arg_params[\"debug_steps\"] = 10\n",
    "arg_params[\"use_cuda\"] = True\n",
    "arg_params[\"checkpoint_folder\"] = \"/scratch/sshrestha8/Workshop/Day4/saving_directories/checkpoints\"\n",
    "arg_params[\"resume\"] = os.path.join(arg_params[\"checkpoint_folder\"], \"mb1-ssd-Epoch-99-Loss-0.8893855273723602.pth\")\n",
    "arg_params[\"log_level\"] = \"info\"\n",
    "arg_params[\"tensorboard\"] = \"/scratch/sshrestha8/Workshop/Day4/saving_directories/tensorboard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f14e46d-8b0b-40aa-8d2b-ab5b71b4fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotDict(dict):\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self:\n",
    "            return self[attr]\n",
    "        else:\n",
    "            raise AttributeError(f\"'DotDict' object has no attribute '{attr}'\")\n",
    "\n",
    "args = DotDict(arg_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a75f95-6731-4de9-81e1-3a14529e46de",
   "metadata": {},
   "source": [
    "Initializing log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8de15c2-b2af-4627-a67d-8362638555f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=getattr(logging, args.log_level.upper(), logging.INFO),\n",
    "                    format='%(asctime)s - %(message)s', datefmt=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74ab62-b5d9-4f72-a387-beb19920445b",
   "metadata": {},
   "source": [
    "Initializing tensorboard location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a814a62-5b70-40d7-ade4-2ed5f273518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = SummaryWriter(log_dir=os.path.join(args.tensorboard, f\"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"))\n",
    "if not arg_params[\"tensorboard\"]:\n",
    "    os.mkdir(arg_params[\"tensorboard\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7056c6-17ac-465b-b6e3-92fef04e703c",
   "metadata": {},
   "source": [
    "set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d705e2a-5e86-4214-99ca-ab3fe17a67b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() and args.use_cuda else \"cpu\")\n",
    "if args.use_cuda and torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    logging.info(\"Using CUDA...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad9470f8-34cd-490f-b7fe-34484a849e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, net, criterion, optimizer, device, debug_steps=100, epoch=-1):\n",
    "    net.train(True)\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_regression_loss = 0.0\n",
    "    train_classification_loss = 0.0\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    \n",
    "    num_batches = 0\n",
    "    \n",
    "    for i, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        confidence, locations = net(images)\n",
    "        \n",
    "        regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)\n",
    "        loss = regression_loss + classification_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_regression_loss += regression_loss.item()\n",
    "        train_classification_loss += classification_loss.item()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "\n",
    "        if i and i % debug_steps == 0:\n",
    "            avg_loss = running_loss / debug_steps\n",
    "            avg_reg_loss = running_regression_loss / debug_steps\n",
    "            avg_clf_loss = running_classification_loss / debug_steps\n",
    "            logging.info(\n",
    "                f\"Epoch: {epoch}, Step: {i}/{len(loader)}, \" +\n",
    "                f\"Avg Loss: {avg_loss:.4f}, \" +\n",
    "                f\"Avg Regression Loss {avg_reg_loss:.4f}, \" +\n",
    "                f\"Avg Classification Loss: {avg_clf_loss:.4f}\"\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "            running_regression_loss = 0.0\n",
    "            running_classification_loss = 0.0\n",
    "\n",
    "        num_batches += 1\n",
    "        \n",
    "    train_loss /= num_batches\n",
    "    train_regression_loss /= num_batches\n",
    "    train_classification_loss /= num_batches\n",
    "    \n",
    "    logging.info(\n",
    "        f\"Epoch: {epoch}, \" +\n",
    "        f\"Training Loss: {train_loss:.4f}, \" +\n",
    "        f\"Training Regression Loss {train_regression_loss:.4f}, \" +\n",
    "        f\"Training Classification Loss: {train_classification_loss:.4f}\"\n",
    "    )\n",
    "     \n",
    "    tensorboard.add_scalar('Loss/train', train_loss, epoch)\n",
    "    tensorboard.add_scalar('Regression Loss/train', train_regression_loss, epoch)\n",
    "    tensorboard.add_scalar('Classification Loss/train', train_classification_loss, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbc96ea6-9e5f-4c1e-a4b1-9a07af22758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, net, criterion, device):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    num = 0\n",
    "    for _, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "        num += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            confidence, locations = net(images)\n",
    "            regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)\n",
    "            loss = regression_loss + classification_loss\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "    \n",
    "    return running_loss / num, running_regression_loss / num, running_classification_loss / num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae1aa2e4-efe8-425c-b19b-633a722cda16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-21 18:35:14 - {'dataset_type': 'open_images', 'datasets': ['/scratch/sshrestha8/Workshop/Day4/data'], 'balance_data': True, 'net': 'mb1-ssd', 'resolution': 300, 'freeze_base_net': True, 'freeze_net': True, 'mb2_width_mult': 1.0, 'base_net': '', 'pretrained_ssd': 'models/mobilenet-v1-ssd-mp-0_675.pth', 'lr': 0.01, 'momentum': 0.9, 'weight_decay': 0.0005, 'gamma': 0.1, 'base_net_lr': 0.001, 'extra_layers_lr': None, 'scheduler': 'cosine', 'milestones': '80,100', 't_max': 100, 'batch_size': 4, 'num_epochs': 100, 'num_workers': 2, 'validation_epochs': 1, 'validation_mean_ap': True, 'debug_steps': 10, 'use_cuda': True, 'checkpoint_folder': '/scratch/sshrestha8/Workshop/Day4/saving_directories/checkpoints', 'resume': '/scratch/sshrestha8/Workshop/Day4/saving_directories/checkpoints/mb1-ssd-Epoch-99-Loss-0.8893855273723602.pth', 'log_level': 'info', 'tensorboard': '/scratch/sshrestha8/Workshop/Day4/saving_directories/tensorboard'}\n",
      "2023-07-21 18:35:14 - model resolution 300x300\n",
      "2023-07-21 18:35:14 - SSDSpec(feature_map_size=19, shrinkage=16, box_sizes=SSDBoxSizes(min=60, max=105), aspect_ratios=[2, 3])\n",
      "2023-07-21 18:35:14 - SSDSpec(feature_map_size=10, shrinkage=32, box_sizes=SSDBoxSizes(min=105, max=150), aspect_ratios=[2, 3])\n",
      "2023-07-21 18:35:14 - SSDSpec(feature_map_size=5, shrinkage=64, box_sizes=SSDBoxSizes(min=150, max=195), aspect_ratios=[2, 3])\n",
      "2023-07-21 18:35:14 - SSDSpec(feature_map_size=3, shrinkage=100, box_sizes=SSDBoxSizes(min=195, max=240), aspect_ratios=[2, 3])\n",
      "2023-07-21 18:35:14 - SSDSpec(feature_map_size=2, shrinkage=150, box_sizes=SSDBoxSizes(min=240, max=285), aspect_ratios=[2, 3])\n",
      "2023-07-21 18:35:14 - SSDSpec(feature_map_size=1, shrinkage=300, box_sizes=SSDBoxSizes(min=285, max=330), aspect_ratios=[2, 3])\n",
      "2023-07-21 18:35:14 - Prepare training datasets.\n",
      "2023-07-21 18:35:14 - Dataset Summary:Number of Images: 101\n",
      "Minimum Number of Images for a Class: 36\n",
      "Label Distribution:\n",
      "\tLeft: 36\n",
      "\tRight: 48\n",
      "\tStop: 54\n",
      "2023-07-21 18:35:14 - Stored labels into file /scratch/sshrestha8/Workshop/Day4/saving_directories/checkpoints/labels.txt.\n",
      "2023-07-21 18:35:14 - Train dataset size: 101\n",
      "2023-07-21 18:35:14 - Prepare Validation datasets.\n",
      "2023-07-21 18:35:14 - Dataset Summary:Number of Images: 27\n",
      "Minimum Number of Images for a Class: -1\n",
      "Label Distribution:\n",
      "\tLeft: 8\n",
      "\tRight: 14\n",
      "\tStop: 9\n",
      "2023-07-21 18:35:14 - Validation dataset size: 27\n",
      "2023-07-21 18:35:14 - Build network.\n",
      "2023-07-21 18:35:14 - Freeze base net.\n",
      "2023-07-21 18:35:14 - Resuming from the model /scratch/sshrestha8/Workshop/Day4/saving_directories/checkpoints/mb1-ssd-Epoch-99-Loss-0.8893855273723602.pth\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/sshrestha8/Workshop/Day4/saving_directories/checkpoints/mb1-ssd-Epoch-99-Loss-0.8893855273723602.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 136\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mresume:\n\u001b[1;32m    135\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResuming from the model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mresume\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m     \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mbase_net:\n\u001b[1;32m    138\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInit from base net \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mbase_net\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/new_workshop_folder/summer_workshop_2023/Day5/Morning-Session-1/Hands-on/vision/ssd/ssd.py:149\u001b[0m, in \u001b[0;36mSSD.load\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m, model):\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/userapp/virtualenv/torch_ssd_env/venv/lib/python3.9/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/userapp/virtualenv/torch_ssd_env/venv/lib/python3.9/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/userapp/virtualenv/torch_ssd_env/venv/lib/python3.9/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/sshrestha8/Workshop/Day4/saving_directories/checkpoints/mb1-ssd-Epoch-99-Loss-0.8893855273723602.pth'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    timer = Timer()\n",
    "\n",
    "    logging.info(args)\n",
    "    \n",
    "    # make sure that the checkpoint output dir exists\n",
    "    if args.checkpoint_folder:\n",
    "        args.checkpoint_folder = os.path.expanduser(args.checkpoint_folder)\n",
    "\n",
    "        if not os.path.exists(args.checkpoint_folder):\n",
    "            os.mkdir(args.checkpoint_folder)\n",
    "            \n",
    "    # select the network architecture and config     \n",
    "    if args.net == 'vgg16-ssd':\n",
    "        create_net = create_vgg_ssd\n",
    "        config = vgg_ssd_config\n",
    "    elif args.net == 'mb1-ssd':\n",
    "        create_net = create_mobilenetv1_ssd\n",
    "        config = mobilenetv1_ssd_config\n",
    "        config.set_image_size(args.resolution)\n",
    "    elif args.net == 'mb1-ssd-lite':\n",
    "        create_net = create_mobilenetv1_ssd_lite\n",
    "        config = mobilenetv1_ssd_config\n",
    "    elif args.net == 'sq-ssd-lite':\n",
    "        create_net = create_squeezenet_ssd_lite\n",
    "        config = squeezenet_ssd_config\n",
    "    elif args.net == 'mb2-ssd-lite':\n",
    "        create_net = lambda num: create_mobilenetv2_ssd_lite(num, width_mult=args.mb2_width_mult)\n",
    "        config = mobilenetv1_ssd_config\n",
    "    else:\n",
    "        logging.fatal(\"The net type is wrong.\")\n",
    "        parser.print_help(sys.stderr)\n",
    "        sys.exit(1)\n",
    "        \n",
    "    # create data transforms for train/test/val\n",
    "    train_transform = TrainAugmentation(config.image_size, config.image_mean, config.image_std)\n",
    "    target_transform = MatchPrior(config.priors, config.center_variance,\n",
    "                                  config.size_variance, 0.5)\n",
    "\n",
    "    test_transform = TestTransform(config.image_size, config.image_mean, config.image_std)\n",
    "\n",
    "    # load datasets (could be multiple)\n",
    "    logging.info(\"Prepare training datasets.\")\n",
    "    datasets = []\n",
    "    for dataset_path in args.datasets:\n",
    "        if args.dataset_type == 'open_images':\n",
    "\n",
    "            dataset = ImagesDataset(dataset_path,\n",
    "                 transform=train_transform, target_transform=target_transform,\n",
    "                 dataset_type=\"train\", balance_data=args.balance_data)\n",
    "            label_file = os.path.join(args.checkpoint_folder, \"labels.txt\")\n",
    "            store_labels(label_file, dataset.class_names)\n",
    "            logging.info(dataset)\n",
    "            num_classes = len(dataset.class_names)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Dataset type {args.dataset_type} is not supported.\")\n",
    "        datasets.append(dataset)\n",
    "        \n",
    "    # create training dataset\n",
    "    logging.info(f\"Stored labels into file {label_file}.\")\n",
    "    train_dataset = ConcatDataset(datasets)\n",
    "    logging.info(\"Train dataset size: {}\".format(len(train_dataset)))\n",
    "    train_loader = DataLoader(train_dataset, args.batch_size,\n",
    "                              num_workers=args.num_workers,\n",
    "                              shuffle=True)\n",
    "                           \n",
    "    # create validation dataset                           \n",
    "    logging.info(\"Prepare Validation datasets.\")\n",
    "    if args.dataset_type == 'open_images':\n",
    "        val_dataset = ImagesDataset(dataset_path,\n",
    "                                        transform=test_transform, target_transform=target_transform,\n",
    "                                        dataset_type=\"test\")\n",
    "        logging.info(val_dataset)\n",
    "    logging.info(\"Validation dataset size: {}\".format(len(val_dataset)))\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, args.batch_size,\n",
    "                            num_workers=args.num_workers,\n",
    "                            shuffle=False)\n",
    "                      \n",
    "    # create the network\n",
    "    logging.info(\"Build network.\")\n",
    "    net = create_net(num_classes)\n",
    "    min_loss = -10000.0\n",
    "    last_epoch = -1\n",
    "\n",
    "    # prepare eval dataset (for mAP computation)\n",
    "    # if args.validation_mean_ap:\n",
    "    #     if args.dataset_type == 'open_images':\n",
    "    #         eval_dataset = ImagesDataset(dataset_path, dataset_type=\"test\")\n",
    "    #     eval = MeanAPEvaluator(eval_dataset, net, arch=args.net, eval_dir=os.path.join(args.checkpoint_folder, 'eval_results'))\n",
    "        \n",
    "    # freeze certain layers (if requested)\n",
    "    base_net_lr = args.base_net_lr if args.base_net_lr is not None else args.lr\n",
    "    extra_layers_lr = args.extra_layers_lr if args.extra_layers_lr is not None else args.lr\n",
    "    \n",
    "    if args.freeze_base_net:\n",
    "        logging.info(\"Freeze base net.\")\n",
    "        freeze_net_layers(net.base_net)\n",
    "        params = itertools.chain(net.source_layer_add_ons.parameters(), net.extras.parameters(),\n",
    "                                 net.regression_headers.parameters(), net.classification_headers.parameters())\n",
    "        params = [\n",
    "            {'params': itertools.chain(\n",
    "                net.source_layer_add_ons.parameters(),\n",
    "                net.extras.parameters()\n",
    "            ), 'lr': extra_layers_lr},\n",
    "            {'params': itertools.chain(\n",
    "                net.regression_headers.parameters(),\n",
    "                net.classification_headers.parameters()\n",
    "            )}\n",
    "        ]\n",
    "    elif args.freeze_net:\n",
    "        freeze_net_layers(net.base_net)\n",
    "        freeze_net_layers(net.source_layer_add_ons)\n",
    "        freeze_net_layers(net.extras)\n",
    "        params = itertools.chain(net.regression_headers.parameters(), net.classification_headers.parameters())\n",
    "        logging.info(\"Freeze all the layers except prediction heads.\")\n",
    "    else:\n",
    "        params = [\n",
    "            {'params': net.base_net.parameters(), 'lr': base_net_lr},\n",
    "            {'params': itertools.chain(\n",
    "                net.source_layer_add_ons.parameters(),\n",
    "                net.extras.parameters()\n",
    "            ), 'lr': extra_layers_lr},\n",
    "            {'params': itertools.chain(\n",
    "                net.regression_headers.parameters(),\n",
    "                net.classification_headers.parameters()\n",
    "            )}\n",
    "        ]\n",
    "\n",
    "    # load a previous model checkpoint (if requested)\n",
    "    timer.start(\"Load Model\")\n",
    "    \n",
    "    if args.resume:\n",
    "        logging.info(f\"Resuming from the model {args.resume}\")\n",
    "        net.load(args.resume)\n",
    "    elif args.base_net:\n",
    "        logging.info(f\"Init from base net {args.base_net}\")\n",
    "        net.init_from_base_net(args.base_net)\n",
    "    elif args.pretrained_ssd:\n",
    "        logging.info(f\"Init from pretrained SSD {args.pretrained_ssd}\")\n",
    "        \n",
    "        if not os.path.exists(args.pretrained_ssd) and args.pretrained_ssd == DEFAULT_PRETRAINED_MODEL:\n",
    "            os.system(f\"wget --quiet --show-progress --progress=bar:force:noscroll --no-check-certificate https://nvidia.box.com/shared/static/djf5w54rjvpqocsiztzaandq1m3avr7c.pth -O {DEFAULT_PRETRAINED_MODEL}\")\n",
    "\n",
    "        net.init_from_pretrained_ssd(args.pretrained_ssd)\n",
    "        \n",
    "    logging.info(f'Took {timer.end(\"Load Model\"):.2f} seconds to load the model.')\n",
    "\n",
    "    # move the model to GPU\n",
    "    net.to(DEVICE)\n",
    "\n",
    "    # define loss function and optimizer\n",
    "    criterion = MultiboxLoss(config.priors, iou_threshold=0.5, neg_pos_ratio=3,\n",
    "                             center_variance=0.1, size_variance=0.2, device=DEVICE)\n",
    "                             \n",
    "    optimizer = torch.optim.SGD(params, lr=args.lr, momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "                                \n",
    "    logging.info(f\"Learning rate: {args.lr}, Base net learning rate: {base_net_lr}, \"\n",
    "                 + f\"Extra Layers learning rate: {extra_layers_lr}.\")\n",
    "\n",
    "    # set learning rate policy\n",
    "    if args.scheduler == 'multi-step':\n",
    "        logging.info(\"Uses MultiStepLR scheduler.\")\n",
    "        milestones = [int(v.strip()) for v in args.milestones.split(\",\")]\n",
    "        scheduler = MultiStepLR(optimizer, milestones=milestones,\n",
    "                                                     gamma=0.1, last_epoch=last_epoch)\n",
    "    elif args.scheduler == 'cosine':\n",
    "        logging.info(\"Uses CosineAnnealingLR scheduler.\")\n",
    "        scheduler = CosineAnnealingLR(optimizer, args.t_max, last_epoch=last_epoch)\n",
    "    else:\n",
    "        logging.fatal(f\"Unsupported Scheduler: {args.scheduler}.\")\n",
    "        parser.print_help(sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # train for the desired number of epochs\n",
    "    logging.info(f\"Start training from epoch {last_epoch + 1}.\")\n",
    "    \n",
    "    for epoch in range(last_epoch + 1, args.num_epochs):\n",
    "        train(train_loader, net, criterion, optimizer, device=DEVICE, debug_steps=args.debug_steps, epoch=epoch)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if epoch % args.validation_epochs == 0 or epoch == args.num_epochs - 1:\n",
    "            val_loss, val_regression_loss, val_classification_loss = test(val_loader, net, criterion, DEVICE)\n",
    "            \n",
    "            logging.info(\n",
    "                f\"Epoch: {epoch}, \" +\n",
    "                f\"Validation Loss: {val_loss:.4f}, \" +\n",
    "                f\"Validation Regression Loss {val_regression_loss:.4f}, \" +\n",
    "                f\"Validation Classification Loss: {val_classification_loss:.4f}\"\n",
    "            )\n",
    "                    \n",
    "            tensorboard.add_scalar('Loss/val', val_loss, epoch)\n",
    "            tensorboard.add_scalar('Regression Loss/val', val_regression_loss, epoch)\n",
    "            tensorboard.add_scalar('Classification Loss/val', val_classification_loss, epoch)\n",
    "    \n",
    "            # if args.validation_mean_ap:\n",
    "            #     mean_ap, class_ap = eval.compute()\n",
    "            #     eval.log_results(mean_ap, class_ap, f\"Epoch: {epoch}, \")\n",
    "                        \n",
    "            #     tensorboard.add_scalar('Mean Average Precision/val', mean_ap, epoch)\n",
    "                \n",
    "            #     for i in range(len(class_ap)):\n",
    "            #         tensorboard.add_scalar(f\"Class Average Precision/{eval_dataset.class_names[i+1]}\", class_ap[i], epoch)\n",
    "    \n",
    "            model_path = os.path.join(args.checkpoint_folder, f\"{args.net}-Epoch-{epoch}-Loss-{val_loss}.pth\")\n",
    "            net.save(model_path)\n",
    "            logging.info(f\"Saved model {model_path}\")\n",
    "\n",
    "    logging.info(\"Task done, exiting program.\")\n",
    "    tensorboard.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce64e7c-7ecd-4107-be0b-a03a5af600ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937b4d4-cf78-4b2e-a170-ec884c5679bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eab8c9-9e77-4f9f-80e3-7860a62aa0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34bb985-a76e-4ef2-ba92-eb682a438625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa69ca-e3e6-4838-8c18-a59b8e309467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb60f39-a045-4891-b098-1b00c3c73240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942a20c-3a0f-41fe-ac68-e211538b7eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fadbe-0f65-42b8-975c-bd89931011f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823bc16-06b1-4e43-bba6-bb88c182d0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0770be6-c888-499d-8cc3-ef07c314da12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f797ed5f-d684-45df-b606-0b9022463956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
